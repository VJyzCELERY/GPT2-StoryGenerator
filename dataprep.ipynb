{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd292587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d1877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dataset'\n",
    "local_dir = \"./data/gutenberg\"\n",
    "val_ratio = 0.2\n",
    "shard_size = int(1e8)\n",
    "\n",
    "DATA_CACHE_DIR = local_dir\n",
    "os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05eeece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffers = {\n",
    "    \"val\":  np.empty((shard_size,), dtype=np.uint16),\n",
    "    \"train\": np.empty((shard_size,), dtype=np.uint16)\n",
    "}\n",
    "counts = {\"val\": 0, \"train\": 0}\n",
    "shard_idx = {\"val\": 0, \"train\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46cd3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding('gpt2')\n",
    "eot = enc._special_tokens['<|endoftext|>']\n",
    "\n",
    "def tokenize(doc):\n",
    "    tokens = [eot]\n",
    "    tokens.extend(enc.encode_ordinary(doc['text']))\n",
    "    tokens_np = np.array(tokens)\n",
    "    tokens_np_uint16 = tokens_np.astype(np.uint16)\n",
    "    return tokens_np_uint16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1a91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_PATH,'gutenberg.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc080392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b6d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e945a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fa6b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train shard 0: 100%|█████████▉| 99732750/100000000 [00:40<00:00, 1991366.07tokens/s]\n",
      "train shard 0: 100%|█████████▉| 99930997/100000000 [00:41<00:00, 2423851.70tokens/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "train shard 1: 100%|█████████▉| 99824863/100000000 [00:45<00:00, 2188862.45tokens/s]\n",
      "train shard 2:  69%|██████▉   | 69460670/100000000 [00:30<00:11, 2663121.85tokens/s]"
     ]
    }
   ],
   "source": [
    "counts = {\"val\": 0, \"train\": 0}\n",
    "shard_idx = {\"val\": 0, \"train\": 0}\n",
    "\n",
    "progress = {\"val\": None, \"train\": None}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tokens = tokenize(row)\n",
    "\n",
    "    split = \"val\" if random.random() < val_ratio else \"train\"\n",
    "\n",
    "    buf = buffers[split]\n",
    "    count = counts[split]\n",
    "\n",
    "    if count + len(tokens) < shard_size:\n",
    "        buf[count:count + len(tokens)] = tokens\n",
    "        counts[split] += len(tokens)\n",
    "\n",
    "        if progress[split] is None:\n",
    "            progress[split] = tqdm(total=shard_size, unit='tokens', desc=f\"{split} shard {shard_idx[split]}\")\n",
    "        progress[split].update(len(tokens))\n",
    "\n",
    "    else:\n",
    "        filename = f\"tinystories_{split}_{shard_idx[split]:06d}.npy\"\n",
    "        np.save(os.path.join(DATA_CACHE_DIR, filename), buf[:count])\n",
    "\n",
    "        shard_idx[split] += 1\n",
    "\n",
    "        progress[split] = tqdm(total=shard_size, unit='tokens',\n",
    "                               desc=f\"{split} shard {shard_idx[split]}\")\n",
    "\n",
    "        # Add remainder to new shard\n",
    "        remainder = shard_size - count\n",
    "        buf[:remainder] = tokens[:remainder]\n",
    "        counts[split] = remainder\n",
    "        progress[split].update(remainder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7141b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train shard 2:  70%|██████▉   | 69715321/100000000 [00:43<00:11, 2663121.85tokens/s]"
     ]
    }
   ],
   "source": [
    "for split in [\"val\", \"train\"]:\n",
    "    if counts[split] > 0:\n",
    "        filename = f\"tinystories_{split}_{shard_idx[split]:06d}.npy\"\n",
    "        np.save(os.path.join(DATA_CACHE_DIR, filename),\n",
    "                buffers[split][:counts[split]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
